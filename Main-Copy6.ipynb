{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa1384d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial import ConvexHull\n",
    "import math\n",
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "import random\n",
    "import cvxpy as cp\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "import sympy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7de1655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PlatonicCoordinates as pcoord\n",
    "import ArchimedeanCoordinates as acoord\n",
    "import CatalanCoordinates as ccoord\n",
    "import JohnsonCoordinates as jcoord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59766c33",
   "metadata": {},
   "source": [
    "# Polyhedron Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dfa6d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either in 2D or 3D translate each set of coordinates by a vector of translations\n",
    "def Translate2D(pts, delta):\n",
    "    for row in pts:\n",
    "        row += delta\n",
    "    return pts\n",
    "    \n",
    "    \n",
    "def Translate3D(pts, delta):\n",
    "    for row in pts:\n",
    "        row += delta\n",
    "    return pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6dada76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take in a vector of translations, using the below translation matrix\n",
    "# Rotating counterclockwise each way\n",
    "def TranslationMatrix(x): \n",
    "    return np.array([[np.cos(x), -np.sin(x)], [np.sin(x), np.cos(x)]])\n",
    "\n",
    "def Rotate2D(pts, theta):\n",
    "    newPts = []\n",
    "    for row in pts:\n",
    "        transMatrix = TranslationMatrix(theta)\n",
    "        row = np.matmul(TranslationMatrix(theta), row)\n",
    "        newPts.append(row)\n",
    "    return np.array(newPts)\n",
    "    \n",
    "\n",
    "def Rotate3D(pts, theta):\n",
    "    newPts = []\n",
    "    for row in pts:\n",
    "        xRotated = np.matmul(TranslationMatrix(theta[0]), row[1:3]) \n",
    "        newRow1 = np.array([row[0], xRotated[0], xRotated[1]])\n",
    "\n",
    "        yRotated = np.matmul(TranslationMatrix(theta[1]),newRow1[[2,0]])\n",
    "        newRow2 = np.array([yRotated[1], newRow1[1], yRotated[0]])\n",
    "    \n",
    "        zRotated = np.matmul(TranslationMatrix(theta[2]), newRow2[0:2])\n",
    "        newRow3 = np.array([zRotated[0], zRotated[1], newRow2[2]])\n",
    "        \n",
    "        newPts.append(newRow3)\n",
    "\n",
    "    return np.array(newPts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbe42c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale a polyhedron to be mu times larger.\n",
    "# Returning a new list of points for the resulting 2D or 3D polyhedron\n",
    "def Rescale2D(pts, mu):\n",
    "    pts *= mu\n",
    "    return pts\n",
    "    \n",
    "def Rescale3D(pts, mu):\n",
    "    pts *= mu\n",
    "    return pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b163f5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project a 3D polyhedron down onto its shadow (dropping the z component)\n",
    "# Returning a new list of points for the resulting 2D polyhedron\n",
    "def Projection(pts):\n",
    "    newpts = pts[:, :-1]\n",
    "    return newpts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d396f48",
   "metadata": {},
   "source": [
    "# Passage Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0e09723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Graham scan to find the convex hull\n",
    "def GrahamScan(points):\n",
    "    def CrossProduct(p1, p2, p3):\n",
    "        return (p2[0] - p1[0]) * (p3[1] - p1[1]) - (p2[1] - p1[1]) * (p3[0] - p1[0])\n",
    "\n",
    "    def AngleWithPivot(point):\n",
    "        return math.atan2(point[1] - pivot[1], point[0] - pivot[0])\n",
    "\n",
    "    pivot = min(points, key=lambda point: (point[1], point[0]))\n",
    "\n",
    "    sorted_points = sorted(points, key=AngleWithPivot)\n",
    "\n",
    "    convex_hull = [pivot, sorted_points[0]]\n",
    "\n",
    "    for i in range(1, len(sorted_points)):\n",
    "        while (\n",
    "            len(convex_hull) > 1\n",
    "            and CrossProduct(convex_hull[-2], convex_hull[-1], sorted_points[i]) <= 0\n",
    "        ):\n",
    "            convex_hull.pop()\n",
    "        convex_hull.append(sorted_points[i])\n",
    "\n",
    "    return convex_hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ddbf8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the largest mu such that rescaling the first given 2D polyhedron lies entirely inside the second given polyhedron.\n",
    "def LargestContainment(pts_inner, pts_outer):\n",
    "    innerProj = Projection(pts_inner)\n",
    "    outerProj = Projection(pts_outer)\n",
    "    innerHull = GrahamScan(innerProj)\n",
    "    outerHull = GrahamScan(outerProj)\n",
    "    \n",
    "    store = 1000\n",
    "    # Go through each point in our outer hull, making sure they're not the same point\n",
    "    for i in range(len(outerHull)):\n",
    "        p1 = outerHull[i]\n",
    "        p2 = outerHull[(i+1)%len(outerHull)]\n",
    "        if p1[0] == p2[0] and p1[1] == p2[1]:\n",
    "            continue\n",
    "        matrix = np.matrix([[p1[0], p1[1]], [p2[0], p2[1]]])\n",
    "        matrixInverse = np.linalg.inv(matrix)\n",
    "        b = ([[1], [1]])\n",
    "        product = np.matmul(matrixInverse, b)\n",
    "        # This tells us the line that defines our outer point\n",
    "        a1 = product[0,0]\n",
    "        a2 = product[1,0]\n",
    "        # Assumes that only the points on the boundary would matter \n",
    "        # Val tells us where we are with our point in relation to the line\n",
    "        for j in range(len(innerHull)):\n",
    "            o1 = innerHull[j]\n",
    "            val = a1*o1[0] + a2*o1[1]\n",
    "            if val > 0 and 1/val < store:\n",
    "                store = (1/val)\n",
    "    return store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4a936fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a set of rotations and translations return how much we can rescale by\n",
    "def MaxShapeMu(delta1, delta2, theta11, theta12, theta13, theta21, theta22, theta23, P):\n",
    "    delta_set = np.array([delta1, delta2, 0])\n",
    "    theta1_set = np.array([theta11, theta12, theta13])\n",
    "    theta2_set = np.array([theta21, theta22, theta23])\n",
    "    P1 = Rotate3D(P, theta1_set)\n",
    "    P2 = Translate3D(P1, delta_set)\n",
    "    P3 = Rotate3D(P, theta2_set)\n",
    "    return LargestContainment(P2, P3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36c802f",
   "metadata": {},
   "source": [
    "# Gradient Setup and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e3b9b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each trio of inner point and outer edge, symbolically compute the gradient and store it in a matrix to return\n",
    "def GradientVals(a1, a2, a3, a4, a5, a6, a7, a8, trios, P):\n",
    "    \n",
    "    grad_mat = []\n",
    "    \n",
    "    for trio in trios:\n",
    "        # Symbolic constants\n",
    "        v1, v2, v3, v4, v5, v6, v7, v8 = sp.symbols('v1 v2 v3 v4 v5 v6 v7 v8')\n",
    "        \n",
    "        P1 = P[trio[0]]\n",
    "        P2 = P[trio[1]]\n",
    "        P3 = P[trio[2]]\n",
    "        # Our three points\n",
    "        x1, y1, z1 = P1\n",
    "        x2, y2, z2 = P2\n",
    "        x3, y3, z3 = P3\n",
    "        \n",
    "        bigP = []\n",
    "        bigP.append(P1)\n",
    "        bigP.append(P2)\n",
    "        bigP.append(P3)\n",
    "        \n",
    "        # Set up what our expression looks like after rotations and translations\n",
    "        x1new = (sp.cos(v4)*sp.cos(v5))*x1 + (sp.cos(v5)*sp.sin(v3)*sp.sin(v4) - sp.cos(v3)*sp.sin(v5))*y1 + (sp.sin(v3)*sp.sin(v5) + sp.cos(v3)*sp.cos(v5)*sp.sin(v4))*z1 + v1\n",
    "        y1new = (sp.cos(v4)*sp.sin(v5))*x1 + (sp.cos(v3)*sp.cos(v5) + sp.sin(v3)*sp.sin(v4)*sp.sin(v5))*y1 + (sp.cos(v3)*sp.sin(v4)*sp.sin(v5) - sp.cos(v5)*sp.sin(v3))*z1 + v2\n",
    "        \n",
    "        x2new = (sp.cos(v7)*sp.cos(v8))*x2 + (sp.cos(v8)*sp.sin(v6)*sp.sin(v7) - sp.cos(v6)*sp.sin(v8))*y2 + (sp.sin(v6)*sp.sin(v8) + sp.cos(v6)*sp.cos(v8)*sp.sin(v7))*z2\n",
    "        y2new = (sp.cos(v7)*sp.sin(v8))*x2 + (sp.cos(v6)*sp.cos(v8) + sp.sin(v6)*sp.sin(v7)*sp.sin(v8))*y2 + (sp.cos(v6)*sp.sin(v7)*sp.sin(v8) - sp.cos(v8)*sp.sin(v6))*z2\n",
    "        \n",
    "        x3new = (sp.cos(v7)*sp.cos(v8))*x3 + (sp.cos(v8)*sp.sin(v6)*sp.sin(v7) - sp.cos(v6)*sp.sin(v8))*y3 + (sp.sin(v6)*sp.sin(v8) + sp.cos(v6)*sp.cos(v8)*sp.sin(v7))*z3\n",
    "        y3new = (sp.cos(v7)*sp.sin(v8))*x3 + (sp.cos(v6)*sp.cos(v8) + sp.sin(v6)*sp.sin(v7)*sp.sin(v8))*y3 + (sp.cos(v6)*sp.sin(v7)*sp.sin(v8) - sp.cos(v8)*sp.sin(v6))*z3\n",
    "\n",
    "        \n",
    "        expression = (x2new*y3new - x3new*y2new) / ((y3new - y2new)*x1new + (x2new - x3new)*y1new)\n",
    "        \n",
    "        variables = [v1, v2, v3, v4, v5, v6, v7, v8]\n",
    "        # Take the gradient with respect to each variable and evaluate those gradients\n",
    "        gradients = [sp.diff(expression, var) for var in variables]\n",
    "    \n",
    "        eval_gradients = [grad.evalf(subs={v1: a1, v2: a2, v3: a3, v4: a4, v5: a5, v6: a6, v7: a7, v8: a8}) for grad in gradients]\n",
    "        \n",
    "        eval_gradients = np.array(eval_gradients, dtype=float)\n",
    "        # Store our gradients in a matrix to be returned\n",
    "        grad_mat.append(eval_gradients)\n",
    "        \n",
    "    return grad_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1622dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through our list of trios (inner point and outer edge) and find the largest\n",
    "# These are the trios whose gradients we will look at\n",
    "def MuVals(delta1, delta2, theta11, theta12, theta13, theta21, theta22, theta23, trios, P):\n",
    "    notable_trios = []\n",
    "    trio_vals = {}\n",
    "    base = 10\n",
    "    \n",
    "    for trio in trios:\n",
    "        P1 = P[trio[0]]\n",
    "        P2 = P[trio[1]]\n",
    "        P3 = P[trio[2]]\n",
    "        # We take in where the points are respectively (i.e. 4th inner point)\n",
    "        # So we must rotate and translate each point in our trio again\n",
    "        delta_set = np.array([delta1, delta2, 0])\n",
    "        theta1_set = np.array([theta11, theta12, theta13])\n",
    "        theta2_set = np.array([theta21, theta22, theta23])\n",
    "                \n",
    "        x1, y1 = Projection(Translate3D((Rotate3D([P1], theta1_set)), delta_set))[0]\n",
    "        x2, y2 = Projection(Rotate3D([P2], theta2_set))[0]\n",
    "        x3, y3 = Projection(Rotate3D([P3], theta2_set))[0]\n",
    "        \n",
    "        muVal = (x2*y3 - x3*y2) / ((y3-y2)*x1 + (x2-x3)*y1)\n",
    "        \n",
    "        trio_key = tuple(trio)\n",
    "        \n",
    "        trio_vals[trio_key] = muVal\n",
    "        # If we have a higher muVal store it\n",
    "        if muVal < base and muVal > 0:\n",
    "            base = muVal\n",
    "    # Send us all of the notable trios\n",
    "    for key in trio_vals:\n",
    "        if trio_vals[key] - base < 0.0001 and trio_vals[key] > 0:\n",
    "            notable_trios.append(key)\n",
    "    \n",
    "    return [notable_trios]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05cc6cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all inner point and outside edge combinations \n",
    "def ConvexHullTrios(delta1, delta2, theta11, theta12, theta13, theta21, theta22, theta23, P):\n",
    "    \n",
    "    delta_set = np.array([delta1, delta2, 0])\n",
    "    theta1_set = np.array([theta11, theta12, theta13])\n",
    "    theta2_set = np.array([theta21, theta22, theta23])\n",
    "    P1 = Rotate3D(P, theta1_set)\n",
    "    P2 = Translate3D(P1, delta_set) \n",
    "    P3 = Rotate3D(P, theta2_set) \n",
    "    \n",
    "    # Use rotations and translations to find the inner and outer points and hulls\n",
    "    # Iterate through them and find the trios to search through\n",
    "    innerProj = Projection(P2)\n",
    "    outerProj = Projection(P3)\n",
    "    innerHull = GrahamScan(innerProj)\n",
    "    outerHull = GrahamScan(outerProj)\n",
    "    \n",
    "    innerList = []\n",
    "    \n",
    "    for point in innerHull:\n",
    "        for i in range(len(innerProj)):\n",
    "            if np.array_equal(point, innerProj[i]):\n",
    "                innerList.append(i)\n",
    "                \n",
    "    outerList = []\n",
    "    \n",
    "    for point in outerHull:\n",
    "        for i in range(len(outerProj)):\n",
    "            if np.array_equal(point, outerProj[i]):\n",
    "                outerList.append(i)\n",
    "                \n",
    "    pairings = []\n",
    "    # Our pairs are all of the inner points combined with an outer edge \n",
    "    for i in range(len(innerList)):\n",
    "        for j in range(len(outerList)):\n",
    "            pairings.append([innerList[i], outerList[j], outerList[(j+1)%len(outerList)]])\n",
    "            \n",
    "            \n",
    "    return pairings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0625f22",
   "metadata": {},
   "source": [
    "# Shape Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f8dc7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a shape this will start a random initailization and use gradient ascent to find the largest rescaling \n",
    "def TestShapeNew(shape):\n",
    "    \n",
    "    # Initialize a random set of rotations and translations    \n",
    "    step = 0.00001\n",
    "    x1 = np.random.uniform(-0.01,0.01)\n",
    "    x2 = np.random.uniform(-0.01,0.01)\n",
    "\n",
    "    x3 = np.random.uniform(0,2 * np.pi)\n",
    "    x4 = np.random.uniform(0,2 * np.pi)\n",
    "    x5 = np.random.uniform(0,2 * np.pi)\n",
    "\n",
    "    x6 = np.random.uniform(0,2 * np.pi)\n",
    "    x7 = np.random.uniform(0,2 * np.pi)\n",
    "    x8 = np.random.uniform(0,2 * np.pi)\n",
    "\n",
    "    a=1.0\n",
    "    \n",
    "    # Iterate a max of 1000 times\n",
    "    for j in range(1000):\n",
    "        grad_mat = []\n",
    "        muVal = 0\n",
    "        # Find our trios, figure out which ones matter, and evaluate their gradients\n",
    "        trios = ConvexHullTrios(x1, x2, x3, x4, x5, x6, x7, x8, shape)\n",
    "        notable_trios = MuVals(x1, x2, x3, x4, x5, x6, x7, x8, trios, shape)[0]\n",
    "        grad_mat = GradientVals(x1, x2, x3, x4, x5, x6, x7, x8, notable_trios, shape)\n",
    "        # If there is only one active gradient this one will do for us\n",
    "        avgGrads = grad_mat[0] \n",
    "\n",
    "        # If there are many active gradients we want the combination with smallest norm\n",
    "        if len(grad_mat)>1: \n",
    "            grad_mat = np.array(grad_mat)\n",
    "            # Objective: Minimize norm of convex combination\n",
    "            # For minimum norm, we minimize (1/2) * y.T * (A * A.T) * y\n",
    "            y = cp.Variable(len(grad_mat))\n",
    "            objective = cp.Minimize((1/2) * cp.norm(grad_mat.T @ y, 2))\n",
    "\n",
    "            # Constraints: weights sum up to 1 and are all non-negative\n",
    "            constraints = [cp.sum(y) == 1, y >= 0]\n",
    "            # Problem setup\n",
    "            problem = cp.Problem(objective, constraints)\n",
    "            # Solve the problem\n",
    "            problem.solve()\n",
    "            # The optimal weights for the minimum norm convex combination\n",
    "            avgGrads = np.matmul(np.transpose(grad_mat), y.value)\n",
    "            \n",
    "        # Use backtracking to scale the gradients\n",
    "        a = a*2 \n",
    "        for i in range(20):\n",
    "            temp1 = x1 + a*avgGrads[0]\n",
    "            temp2 = x2 + a*avgGrads[1]\n",
    "            temp3 = x3 + a*avgGrads[2]\n",
    "            temp4 = x4 + a*avgGrads[3]\n",
    "            temp5 = x5 + a*avgGrads[4]\n",
    "            temp6 = x6 + a*avgGrads[5]\n",
    "            temp7 = x7 + a*avgGrads[6]\n",
    "            temp8 = x8 + a*avgGrads[7]\n",
    "            if MaxShapeMu(temp1, temp2, temp3, temp4, temp5, temp6, temp7, temp8, shape) > MaxShapeMu(x1, x2, x3, x4, x5, x6, x7, x8, shape): \n",
    "                break\n",
    "            else:\n",
    "                a *= 0.5 \n",
    "\n",
    "        # Update our rotations and translations\n",
    "        x1 += avgGrads[0]* a\n",
    "        x2 += avgGrads[1]* a\n",
    "        x3 += avgGrads[2]* a\n",
    "        x4 += avgGrads[3]* a\n",
    "        x5 += avgGrads[4]* a\n",
    "        x6 += avgGrads[5]* a\n",
    "        x7 += avgGrads[6]* a\n",
    "        x8 += avgGrads[7]* a\n",
    "        # Note that our final vector is given with 8 parameters but can be converted to the 7 referenced\n",
    "        # By subracting x8 from both x5 and x8\n",
    "        mu = MaxShapeMu(x1, x2, x3, x4, x5, x6, x7, x8, shape)\n",
    "        final_values = [x1, x2, x3, x4, x5, x6, x7, x8]\n",
    "        # If our a is small enough we won't see much change so we end\n",
    "        if a < 1e-8:\n",
    "            print(j)\n",
    "            break\n",
    "    return [mu, final_values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfbfd6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a set amount of time (in seconds) this will repeatedly run our method on a certain shape\n",
    "# Floor is the highest previously observed mu value\n",
    "# Returns the number of runs, number bigger than previous, number bigger than one (successful passages)\n",
    "# The worst and best rescalings, and the coordinates of the best rescaling\n",
    "def TimedShapeRepeat(runtime, shape, floor):\n",
    "    desired_run_time = runtime\n",
    "    start_time = time.time()\n",
    "    \n",
    "    gd_runs = 0\n",
    "    num_bigger_prev = 0\n",
    "    num_bigger_one = 0\n",
    "    mu_min = 2\n",
    "    mu_max = 0\n",
    "    x_best = []\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        result = TestShapeNew(shape)\n",
    "        \n",
    "        gd_runs += 1\n",
    "        \n",
    "        if result[0] >= 1:\n",
    "            num_bigger_one += 1\n",
    "            \n",
    "        if result[0] >= floor:\n",
    "            num_bigger_prev += 1\n",
    "            \n",
    "        if result[0] > mu_max:\n",
    "            mu_max = result[0]\n",
    "            x_best = result[1]\n",
    "        \n",
    "        if result[0] < mu_min: \n",
    "            mu_min = result[0]\n",
    "            \n",
    "        \n",
    "        if time.time() - start_time > desired_run_time:\n",
    "            return [gd_runs, num_bigger_prev, num_bigger_one, mu_min, mu_max, x_best]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b953775c",
   "metadata": {},
   "source": [
    "# Example Platonic Solid Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c3b1baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.999939447723819,\n",
       " [-1.7275280453558374e-06,\n",
       "  -1.585699721877163e-05,\n",
       "  6.3068378874688715,\n",
       "  3.1840728579007496,\n",
       "  2.74336597108379,\n",
       "  2.6335187174644203,\n",
       "  4.761015037350552,\n",
       "  0.11037630513967467]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tetrahedron = pcoord.Tetrahedron()\n",
    "TestShapeNew(tetrahedron)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b69d3dc",
   "metadata": {},
   "source": [
    "# Example Archimedean Solid Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ccdd0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9829505225998088,\n",
       " [-5.2520052300300055e-05,\n",
       "  0.0001442465690965836,\n",
       "  3.202543237490095,\n",
       "  2.375716685105709,\n",
       "  1.0110423200181573,\n",
       "  3.96696007765517,\n",
       "  6.10183708660667,\n",
       "  5.039381493818418]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhombicosidodecahedron = acoord.Rhombicosidodecahedron()\n",
    "TestShapeNew(rhombicosidodecahedron)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cfbcc7",
   "metadata": {},
   "source": [
    "# Example Catalan Solid Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c369fd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9999413528582246,\n",
       " [-3.9472564390942e-05,\n",
       "  -1.5566716229240612e-05,\n",
       "  2.586382379926849,\n",
       "  5.633387701770723,\n",
       "  5.748971607187731,\n",
       "  5.728024480130392,\n",
       "  3.791421291623753,\n",
       "  2.6073214400541413]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triakis_tetrahedron = ccoord.TriakisTetrahedron()\n",
    "TestShapeNew(triakis_tetrahedron)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c8c237",
   "metadata": {},
   "source": [
    "# Example Johnson Solid Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a361e900",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jcoord' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bigyrate_diminishsed_rhombicosidodecahedron \u001b[38;5;241m=\u001b[39m \u001b[43mjcoord\u001b[49m\u001b[38;5;241m.\u001b[39mBigyrateDiminishedRhombicosidodecahedron()\n\u001b[1;32m      2\u001b[0m TestShapeNew(bigyrate_diminishsed_rhombicosidodecahedron)\n\u001b[1;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jcoord' is not defined"
     ]
    }
   ],
   "source": [
    "bigyrate_diminishsed_rhombicosidodecahedron = jcoord.BigyrateDiminishedRhombicosidodecahedron()\n",
    "TestShapeNew(bigyrate_diminishsed_rhombicosidodecahedron)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d50ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
